{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlexNet(Tensorflow)",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM3V+GunhsW/G/tfj8g0Nv6"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2S0gnoFuKwM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def AlexNet(\n",
        "  input_shape=None,\n",
        "  weights=None,\n",
        "  classes=1000,\n",
        "  classifier_activation='softmax'):\n",
        "  \n",
        "  model = tf.keras.Sequential([\n",
        "      #특징 추출 부분 \n",
        "      #Conv 1\n",
        "      tf.keras.layers.Conv2D(filters=96,\n",
        "                              kernel_size=(11, 11),\n",
        "                              strides=4,\n",
        "                              padding=\"valid\",\n",
        "                              activation=tf.keras.activations.relu,\n",
        "                              input_shape=input_shape),\n",
        "      #Max Pool 1\n",
        "      tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n",
        "                                strides=2,\n",
        "                                padding=\"valid\"),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      #Conv 2\n",
        "      tf.keras.layers.Conv2D(filters=256,\n",
        "                              kernel_size=(5, 5),\n",
        "                              strides=1,\n",
        "                              padding=\"same\",\n",
        "                              activation=tf.keras.activations.relu),\n",
        "      #Max Pool 2\n",
        "      tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n",
        "                                strides=2,\n",
        "                                padding=\"same\"),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      #Conv 3\n",
        "      tf.keras.layers.Conv2D(filters=384,\n",
        "                              kernel_size=(3, 3),\n",
        "                              strides=1,\n",
        "                              padding=\"same\",\n",
        "                              activation=tf.keras.activations.relu),\n",
        "      #Conv 4\n",
        "      tf.keras.layers.Conv2D(filters=384,\n",
        "                              kernel_size=(3, 3),\n",
        "                              strides=1,\n",
        "                              padding=\"same\",\n",
        "                              activation=tf.keras.activations.relu),\n",
        "      #Conv 5\n",
        "      tf.keras.layers.Conv2D(filters=256,\n",
        "                              kernel_size=(3, 3),\n",
        "                              strides=1,\n",
        "                              padding=\"same\",\n",
        "                              activation=tf.keras.activations.relu),\n",
        "      #Max Pool 3\n",
        "      tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n",
        "                                strides=2,\n",
        "                                padding=\"same\"),\n",
        "      tf.keras.layers.BatchNormalization(),\n",
        "      \n",
        "      tf.keras.layers.Flatten(),\n",
        "      \n",
        "      #분류 층 부분\n",
        "      #Fully connected layer 1 \n",
        "      tf.keras.layers.Dense(units=4096,\n",
        "                            activation=tf.keras.activations.relu),\n",
        "      tf.keras.layers.Dropout(rate=0.2),\n",
        "      #Fully connected layer 2\n",
        "      tf.keras.layers.Dense(units=4096,\n",
        "                            activation=tf.keras.activations.relu),\n",
        "      tf.keras.layers.Dropout(rate=0.2),\n",
        "      \n",
        "      #Fully connected layer 3\n",
        "      tf.keras.layers.Dense(units=classes,\n",
        "                            activation=tf.keras.activations.softmax)\n",
        "  ])\n",
        "\n",
        "  return model"
      ]
    }
  ]
}