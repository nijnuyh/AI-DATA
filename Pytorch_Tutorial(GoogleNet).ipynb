{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch Tutorial(GoogleNet)",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPWW9gmSNqeW5C5XU7OI1qh"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GoogleNet\n"
      ],
      "metadata": {
        "id": "g8c1LtZYFggv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 블록"
      ],
      "metadata": {
        "id": "FcV1HBc1GVGU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TObv1aIrFZ2i"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Optional, Tuple, List, Callable, Any\n",
        "\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "from collections import namedtuple"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "__all__ = ['GoogLeNet', 'googlenet', \"GoogLeNetOutputs\", \"_GoogLeNetOutputs\"]\n",
        "\n",
        "model_urls = {\n",
        "    # GoogLeNet ported from TensorFlow\n",
        "    'googlenet': 'https://download.pytorch.org/models/googlenet-1378be20.pth',\n",
        "}\n",
        "\n",
        "GoogLeNetOutputs = namedtuple('GoogLeNetOutputs', ['logits', 'aux_logits2', 'aux_logits1'])\n",
        "GoogLeNetOutputs.__annotations__ = {'logits': Tensor, 'aux_logits2': Optional[Tensor],\n",
        "                                    'aux_logits1': Optional[Tensor]}\n",
        "\n",
        "# Script annotations failed with _GoogleNetOutputs = namedtuple ...\n",
        "# _GoogLeNetOutputs set here for backwards compat\n",
        "_GoogLeNetOutputs = GoogLeNetOutputs\n",
        "\n",
        "\n",
        "def googlenet(pretrained: bool = False, progress: bool = True, **kwargs: Any) -> \"GoogLeNet\":\n",
        "    r\"\"\"GoogLeNet (Inception v1) model architecture from\n",
        "    `\"Going Deeper with Convolutions\" <http://arxiv.org/abs/1409.4842>`_.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "        aux_logits (bool): If True, adds two auxiliary branches that can improve training.\n",
        "            Default: *False* when pretrained is True otherwise *True*\n",
        "        transform_input (bool): If True, preprocesses the input according to the method with which it\n",
        "            was trained on ImageNet. Default: *False*\n",
        "    \"\"\"\n",
        "    if pretrained:\n",
        "        if 'transform_input' not in kwargs:\n",
        "            kwargs['transform_input'] = True\n",
        "        if 'aux_logits' not in kwargs:\n",
        "            kwargs['aux_logits'] = False\n",
        "        if kwargs['aux_logits']:\n",
        "            warnings.warn('auxiliary heads in the pretrained googlenet model are NOT pretrained, '\n",
        "                          'so make sure to train them')\n",
        "        original_aux_logits = kwargs['aux_logits']\n",
        "        kwargs['aux_logits'] = True\n",
        "        kwargs['init_weights'] = False\n",
        "        model = GoogLeNet(**kwargs)\n",
        "        state_dict = load_state_dict_from_url(model_urls['googlenet'],\n",
        "                                              progress=progress)\n",
        "        model.load_state_dict(state_dict)\n",
        "        if not original_aux_logits:\n",
        "            model.aux_logits = False\n",
        "            model.aux1 = None  # type: ignore[assignment]\n",
        "            model.aux2 = None  # type: ignore[assignment]\n",
        "        return model\n",
        "\n",
        "    return GoogLeNet(**kwargs)"
      ],
      "metadata": {
        "id": "NQ-n4i5wFkE1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conv2d 블록"
      ],
      "metadata": {
        "id": "d1pZl5k_Gbpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicConv2d(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        out_channels: int,\n",
        "        **kwargs: Any\n",
        "    ) -> None:\n",
        "        super(BasicConv2d, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
        "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        return F.relu(x, inplace=True)"
      ],
      "metadata": {
        "id": "7UgiMZMSGa0x"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inception 모듈"
      ],
      "metadata": {
        "id": "oPqkjqNfGqJK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inception Module\n",
        "\n",
        "class Inception(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        ch1x1: int,\n",
        "        ch3x3red: int,\n",
        "        ch3x3: int,\n",
        "        ch5x5red: int,\n",
        "        ch5x5: int,\n",
        "        pool_proj: int,\n",
        "        conv_block: Optional[Callable[..., nn.Module]] = None\n",
        "    ) -> None:\n",
        "        super(Inception, self).__init__()\n",
        "        if conv_block is None:\n",
        "            conv_block = BasicConv2d\n",
        "        self.branch1 = conv_block(in_channels, ch1x1, kernel_size=1)\n",
        "\n",
        "        self.branch2 = nn.Sequential(\n",
        "            conv_block(in_channels, ch3x3red, kernel_size=1),\n",
        "            conv_block(ch3x3red, ch3x3, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "        self.branch3 = nn.Sequential(\n",
        "            conv_block(in_channels, ch5x5red, kernel_size=1),\n",
        "            # Here, kernel_size=3 instead of kernel_size=5 is a known bug.\n",
        "            # Please see https://github.com/pytorch/vision/issues/906 for details.\n",
        "            conv_block(ch5x5red, ch5x5, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "        self.branch4 = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1, ceil_mode=True),\n",
        "            conv_block(in_channels, pool_proj, kernel_size=1)\n",
        "        )\n",
        "\n",
        "    def _forward(self, x):\n",
        "        branch1 = self.branch1(x)\n",
        "        branch2 = self.branch2(x)\n",
        "        branch3 = self.branch3(x)\n",
        "        branch4 = self.branch4(x)\n",
        "        print('size of brach1', torch.tensor(branch1).shape)\n",
        "        print('size of branch2', torch.tensor(branch2).shape)\n",
        "        print('size of branch3', torch.tensor(branch3).shape)\n",
        "        print('size of branch4', torch.tensor(branch4).shape)\n",
        "        outputs = [branch1, branch2, branch3, branch4]\n",
        "        return outputs\n",
        "        # N * ch * (H * W)\n",
        "    def forward(self, x):\n",
        "        outputs = self._forward(x)\n",
        "        return torch.cat(outputs, 1)"
      ],
      "metadata": {
        "id": "HcTvuLINGpwo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Auxiliary Classifier(보조 분류기)"
      ],
      "metadata": {
        "id": "cfTWZah4GwnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Auxiliary classifier\n",
        "\n",
        "class InceptionAux(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        num_classes: int,\n",
        "        conv_block: Optional[Callable[..., nn.Module]] = None\n",
        "    ) -> None:\n",
        "        super(InceptionAux, self).__init__()\n",
        "        if conv_block is None:\n",
        "            conv_block = BasicConv2d\n",
        "        self.conv = conv_block(in_channels, 128, kernel_size=1)\n",
        "\n",
        "        self.fc1 = nn.Linear(2048, 1024)\n",
        "        self.fc2 = nn.Linear(1024, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # aux1: N x 512 x 14 x 14, aux2: N x 528 x 14 x 14\n",
        "        x = F.adaptive_avg_pool2d(x, (4, 4))\n",
        "        # aux1: N x 512 x 4 x 4, aux2: N x 528 x 4 x 4\n",
        "        x = self.conv(x)\n",
        "        # N x 128 x 4 x 4\n",
        "        x = torch.flatten(x, 1)\n",
        "        # N x 2048\n",
        "        x = F.relu(self.fc1(x), inplace=True)\n",
        "        # N x 1024\n",
        "        x = F.dropout(x, 0.7, training=self.training)\n",
        "        # N x 1024\n",
        "        x = self.fc2(x)\n",
        "        # N x 1000 (num_classes)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "z2ml1r1QGt0M"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GoogleNet"
      ],
      "metadata": {
        "id": "B9JSz0eUGzLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GoogLeNet(nn.Module):\n",
        "    __constants__ = ['aux_logits', 'transform_input']\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_classes: int = 1000,\n",
        "        aux_logits: bool = True,\n",
        "        transform_input: bool = False,\n",
        "        init_weights: Optional[bool] = None,\n",
        "        blocks: Optional[List[Callable[..., nn.Module]]] = None\n",
        "    ) -> None:\n",
        "        super(GoogLeNet, self).__init__()\n",
        "        if blocks is None:\n",
        "            blocks = [BasicConv2d, Inception, InceptionAux]\n",
        "        if init_weights is None:\n",
        "            # warnings.warn('The default weight initialization of GoogleNet will be changed in future releases of '\n",
        "            #               'torchvision. If you wish to keep the old behavior (which leads to long initialization times'\n",
        "            #               ' due to scipy/scipy#11299), please set init_weights=True.', FutureWarning)\n",
        "            init_weights = True\n",
        "        assert len(blocks) == 3\n",
        "        conv_block = blocks[0]\n",
        "        inception_block = blocks[1]\n",
        "        inception_aux_block = blocks[2]\n",
        "\n",
        "        self.aux_logits = aux_logits\n",
        "        self.transform_input = transform_input\n",
        "\n",
        "        self.conv1 = conv_block(3, 64, kernel_size=7, stride=2, padding=3)\n",
        "        self.maxpool1 = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n",
        "        self.conv2 = conv_block(64, 64, kernel_size=1)\n",
        "        self.conv3 = conv_block(64, 192, kernel_size=3, padding=1)\n",
        "        self.maxpool2 = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.inception3a = inception_block(192, 64, 96, 128, 16, 32, 32)\n",
        "        self.inception3b = inception_block(256, 128, 128, 192, 32, 96, 64)\n",
        "        self.maxpool3 = nn.MaxPool2d(3, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.inception4a = inception_block(480, 192, 96, 208, 16, 48, 64)\n",
        "        self.inception4b = inception_block(512, 160, 112, 224, 24, 64, 64)\n",
        "        self.inception4c = inception_block(512, 128, 128, 256, 24, 64, 64)\n",
        "        self.inception4d = inception_block(512, 112, 144, 288, 32, 64, 64)\n",
        "        self.inception4e = inception_block(528, 256, 160, 320, 32, 128, 128)\n",
        "        self.maxpool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.inception5a = inception_block(832, 256, 160, 320, 32, 128, 128)\n",
        "        self.inception5b = inception_block(832, 384, 192, 384, 48, 128, 128)\n",
        "        if aux_logits:\n",
        "            self.aux1 = inception_aux_block(512, num_classes)\n",
        "            self.aux2 = inception_aux_block(528, num_classes)\n",
        "        else:\n",
        "            self.aux1 = None  # type: ignore[assignment]\n",
        "            self.aux2 = None  # type: ignore[assignment]\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        self.fc = nn.Linear(1024, num_classes)\n",
        "\n",
        "        if init_weights:\n",
        "            self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "                import scipy.stats as stats\n",
        "                X = stats.truncnorm(-2, 2, scale=0.01)\n",
        "                values = torch.as_tensor(X.rvs(m.weight.numel()), dtype=m.weight.dtype)\n",
        "                values = values.view(m.weight.size())\n",
        "                with torch.no_grad():\n",
        "                    m.weight.copy_(values)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _transform_input(self, x):\n",
        "        if self.transform_input:\n",
        "            x_ch0 = torch.unsqueeze(x[:, 0], 1) * (0.229 / 0.5) + (0.485 - 0.5) / 0.5\n",
        "            x_ch1 = torch.unsqueeze(x[:, 1], 1) * (0.224 / 0.5) + (0.456 - 0.5) / 0.5\n",
        "            x_ch2 = torch.unsqueeze(x[:, 2], 1) * (0.225 / 0.5) + (0.406 - 0.5) / 0.5\n",
        "            x = torch.cat((x_ch0, x_ch1, x_ch2), 1)\n",
        "        return x\n",
        "\n",
        "    def _forward(self, x):\n",
        "        # N x 3 x 224 x 224\n",
        "        x = self.conv1(x)\n",
        "        # N x 64 x 112 x 112\n",
        "        x = self.maxpool1(x)\n",
        "        # N x 64 x 56 x 56\n",
        "        x = self.conv2(x)\n",
        "        # N x 64 x 56 x 56\n",
        "        x = self.conv3(x)\n",
        "        # N x 192 x 56 x 56\n",
        "        x = self.maxpool2(x)\n",
        "\n",
        "        # N x 192 x 28 x 28\n",
        "        x = self.inception3a(x)\n",
        "        print('shape after inception3a', x.shape)\n",
        "        # N x 256 x 28 x 28\n",
        "        x = self.inception3b(x)\n",
        "        # N x 480 x 28 x 28\n",
        "        x = self.maxpool3(x)\n",
        "        # N x 480 x 14 x 14\n",
        "        x = self.inception4a(x)\n",
        "        # N x 512 x 14 x 14\n",
        "        aux1 = torch.jit.annotate(Optional[torch.Tensor], None)\n",
        "        if self.aux1 is not None:\n",
        "            if self.training:\n",
        "                aux1 = self.aux1(x)\n",
        "\n",
        "        x = self.inception4b(x)\n",
        "        # N x 512 x 14 x 14\n",
        "        x = self.inception4c(x)\n",
        "        # N x 512 x 14 x 14\n",
        "        x = self.inception4d(x)\n",
        "        # N x 528 x 14 x 14\n",
        "        aux2 = torch.jit.annotate(Optional[torch.Tensor], None)\n",
        "        if self.aux2 is not None:\n",
        "            if self.training:\n",
        "                aux2 = self.aux2(x)\n",
        "\n",
        "        x = self.inception4e(x)\n",
        "        # N x 832 x 14 x 14\n",
        "        x = self.maxpool4(x)\n",
        "        # N x 832 x 7 x 7\n",
        "        x = self.inception5a(x)\n",
        "        # N x 832 x 7 x 7\n",
        "        x = self.inception5b(x)\n",
        "        # N x 1024 x 7 x 7\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        # N x 1024 x 1 x 1\n",
        "        x = torch.flatten(x, 1)\n",
        "        # N x 1024\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "        # N x 1000 (num_classes)\n",
        "        return x, aux2, aux1\n",
        "\n",
        "    @torch.jit.unused\n",
        "    def eager_outputs(self, x, aux2, aux1):\n",
        "        if self.training and self.aux_logits:\n",
        "            return _GoogLeNetOutputs(x, aux2, aux1)\n",
        "        else:\n",
        "            return x   # type: ignore[return-value]\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self._transform_input(x)\n",
        "        x, aux1, aux2 = self._forward(x)\n",
        "        aux_defined = self.training and self.aux_logits\n",
        "        if torch.jit.is_scripting():\n",
        "            if not aux_defined:\n",
        "                warnings.warn(\"Scripted GoogleNet always returns GoogleNetOutputs Tuple\")\n",
        "            return GoogLeNetOutputs(x, aux2, aux1)\n",
        "        else:\n",
        "            return self.eager_outputs(x, aux2, aux1)"
      ],
      "metadata": {
        "id": "JauXAGD-GyDQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 형태"
      ],
      "metadata": {
        "id": "Qyllm99SG518"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ex_net = GoogLeNet()\n",
        "ex_net"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ymv9NCATG7cc",
        "outputId": "b99f35a7-78ca-4c47-f468-701e19e1f3b4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GoogLeNet(\n",
              "  (conv1): BasicConv2d(\n",
              "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (conv2): BasicConv2d(\n",
              "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (conv3): BasicConv2d(\n",
              "    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (inception3a): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception3b): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (inception4a): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception4b): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception4c): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception4d): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception4e): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
              "  (inception5a): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (inception5b): Inception(\n",
              "    (branch1): BasicConv2d(\n",
              "      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch2): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): BasicConv2d(\n",
              "        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
              "      (1): BasicConv2d(\n",
              "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (aux1): InceptionAux(\n",
              "    (conv): BasicConv2d(\n",
              "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "    (fc2): Linear(in_features=1024, out_features=1000, bias=True)\n",
              "  )\n",
              "  (aux2): InceptionAux(\n",
              "    (conv): BasicConv2d(\n",
              "      (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "    (fc2): Linear(in_features=1024, out_features=1000, bias=True)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              "  (fc): Linear(in_features=1024, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, models, transforms\n",
        "# CIFAR-10 dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.Pad(4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32),\n",
        "    transforms.ToTensor()])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
        "                                             train=True, \n",
        "                                             transform=transform,\n",
        "                                             download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
        "                                            train=False, \n",
        "                                            transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=100, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=100, \n",
        "                                          shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOWijjc-G71I",
        "outputId": "48d3af28-c65d-483c-9ab8-73f5e0b879a4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "output = ex_net(images)\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_LVGPiHHAbe",
        "outputId": "692eb334-0d2c-4cfa-baaf-241d5dd14610"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of brach1 torch.Size([100, 64, 4, 4])\n",
            "size of branch2 torch.Size([100, 128, 4, 4])\n",
            "size of branch3 torch.Size([100, 32, 4, 4])\n",
            "size of branch4 torch.Size([100, 32, 4, 4])\n",
            "shape after inception3a torch.Size([100, 256, 4, 4])\n",
            "size of brach1 torch.Size([100, 128, 4, 4])\n",
            "size of branch2 torch.Size([100, 192, 4, 4])\n",
            "size of branch3 torch.Size([100, 96, 4, 4])\n",
            "size of branch4 torch.Size([100, 64, 4, 4])\n",
            "size of brach1 torch.Size([100, 192, 2, 2])\n",
            "size of branch2 torch.Size([100, 208, 2, 2])\n",
            "size of branch3 torch.Size([100, 48, 2, 2])\n",
            "size of branch4 torch.Size([100, 64, 2, 2])\n",
            "size of brach1 torch.Size([100, 160, 2, 2])\n",
            "size of branch2 torch.Size([100, 224, 2, 2])\n",
            "size of branch3 torch.Size([100, 64, 2, 2])\n",
            "size of branch4 torch.Size([100, 64, 2, 2])\n",
            "size of brach1 torch.Size([100, 128, 2, 2])\n",
            "size of branch2 torch.Size([100, 256, 2, 2])\n",
            "size of branch3 torch.Size([100, 64, 2, 2])\n",
            "size of branch4 torch.Size([100, 64, 2, 2])\n",
            "size of brach1 torch.Size([100, 112, 2, 2])\n",
            "size of branch2 torch.Size([100, 288, 2, 2])\n",
            "size of branch3 torch.Size([100, 64, 2, 2])\n",
            "size of branch4 torch.Size([100, 64, 2, 2])\n",
            "size of brach1 torch.Size([100, 256, 2, 2])\n",
            "size of branch2 torch.Size([100, 320, 2, 2])\n",
            "size of branch3 torch.Size([100, 128, 2, 2])\n",
            "size of branch4 torch.Size([100, 128, 2, 2])\n",
            "size of brach1 torch.Size([100, 256, 1, 1])\n",
            "size of branch2 torch.Size([100, 320, 1, 1])\n",
            "size of branch3 torch.Size([100, 128, 1, 1])\n",
            "size of branch4 torch.Size([100, 128, 1, 1])\n",
            "size of brach1 torch.Size([100, 384, 1, 1])\n",
            "size of branch2 torch.Size([100, 384, 1, 1])\n",
            "size of branch3 torch.Size([100, 128, 1, 1])\n",
            "size of branch4 torch.Size([100, 128, 1, 1])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GoogLeNetOutputs(logits=tensor([[ 0.0570, -0.1514,  0.3144,  ...,  0.2306,  0.0089,  0.4165],\n",
              "        [ 0.0800,  0.1326,  0.1920,  ...,  0.2627,  0.0175,  0.3505],\n",
              "        [ 0.1155, -0.1217,  1.5220,  ..., -0.0499, -0.0880,  0.8622],\n",
              "        ...,\n",
              "        [ 0.5148, -0.2714,  0.2780,  ...,  0.1289, -0.5191,  0.0437],\n",
              "        [ 0.2096, -0.2727,  0.2090,  ...,  0.0016, -0.0206,  0.2261],\n",
              "        [ 0.1383, -0.4410,  0.2347,  ...,  0.1395, -0.1967,  0.2674]],\n",
              "       grad_fn=<AddmmBackward0>), aux_logits2=tensor([[ 0.0438, -0.0133,  0.2968,  ...,  0.1947, -0.2322, -0.0006],\n",
              "        [ 0.1332,  0.1803, -0.2225,  ...,  0.0549, -0.1389,  0.0594],\n",
              "        [ 0.0877,  0.0603,  0.2933,  ..., -0.2048,  0.3954, -0.0272],\n",
              "        ...,\n",
              "        [ 0.0382,  0.2453,  0.0966,  ..., -0.0751,  0.0326,  0.0880],\n",
              "        [ 0.0529, -0.0025, -0.0350,  ..., -0.0519, -0.0572,  0.0348],\n",
              "        [ 0.0363, -0.0557,  0.0215,  ..., -0.0988,  0.1228,  0.0057]],\n",
              "       grad_fn=<AddmmBackward0>), aux_logits1=tensor([[ 0.1287,  0.0167,  0.0686,  ...,  0.1420,  0.0132, -0.0049],\n",
              "        [ 0.0532,  0.1382, -0.0642,  ...,  0.0534, -0.0114, -0.0523],\n",
              "        [ 0.0414,  0.0845,  0.5201,  ...,  0.1775, -0.3717, -0.0808],\n",
              "        ...,\n",
              "        [-0.0540,  0.0043,  0.0185,  ...,  0.1751,  0.1403,  0.0683],\n",
              "        [-0.0179,  0.0927,  0.0360,  ...,  0.0568,  0.0524, -0.1257],\n",
              "        [ 0.1538, -0.0712,  0.0064,  ..., -0.0516, -0.1944, -0.0905]],\n",
              "       grad_fn=<AddmmBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pretrained 모델을 사용한 학습\n",
        "* 실습 시에는 '런타임 --> 런타임 다시 시작'을 한 후 진행해주세요"
      ],
      "metadata": {
        "id": "deknJLZMHZ8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "model = torch.hub.load('pytorch/vision:v0.6.0', 'googlenet', pretrained=True)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpvGE0BxHCvu",
        "outputId": "5b255b16-f5eb-43f4-859f-a9b6f69125e0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GoogLeNet(\n",
            "  (conv1): BasicConv2d(\n",
            "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "  (conv2): BasicConv2d(\n",
            "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv3): BasicConv2d(\n",
            "    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "  (inception3a): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception3b): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "  (inception4a): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception4b): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception4c): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception4d): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception4e): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "  (inception5a): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (inception5b): Inception(\n",
            "    (branch1): BasicConv2d(\n",
            "      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (branch2): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch3): Sequential(\n",
            "      (0): BasicConv2d(\n",
            "        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (branch4): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
            "      (1): BasicConv2d(\n",
            "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (aux1): None\n",
            "  (aux2): None\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (fc): Linear(in_features=1024, out_features=1000, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.6.0\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=GoogLeNet_Weights.IMAGENET1K_V1`. You can also use `weights=GoogLeNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 10)\n",
        "\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rz5WQ8zzJeh6",
        "outputId": "31d9a3dc-9cce-4489-ceed-9e5aaac826f6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 80\n",
        "learning_rate = 0.001\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Pad(4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32),\n",
        "    transforms.ToTensor()])"
      ],
      "metadata": {
        "id": "BPHR_u5PJk63"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR-10 dataset\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
        "                                             train=True, \n",
        "                                             transform=transform,\n",
        "                                             download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
        "                                            train=False, \n",
        "                                            transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=100, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=100, \n",
        "                                          shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOo-tqsoJnv4",
        "outputId": "76228314-d0b4-4f5b-c0fe-e8dc713985cc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, dataloaders, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # 각 에폭(epoch)은 학습 단계와 검증 단계를 갖습니다.\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # 모델을 학습 모드로 설정\n",
        "            else:\n",
        "                model.eval()   # 모델을 평가 모드로 설정\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # 데이터를 반복\n",
        "            for inputs, labels in dataloaders:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # 매개변수 경사도를 0으로 설정\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # 순전파\n",
        "                # 학습 시에만 연산 기록을 추적\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # 학습 단계인 경우 역전파 + 최적화\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # 통계\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # 모델을 깊은 복사(deep copy)함\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # 가장 나은 모델 가중치를 불러옴\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "metadata": {
        "id": "OY-NQs_dJpjf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = train_model(model, criterion, train_loader, optimizer, exp_lr_scheduler,\n",
        "                       num_epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYNLrYZ8JshB",
        "outputId": "a50bfd91-127d-4ae0-dfd4-f2ad7943c69a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24\n",
            "----------\n",
            "train Loss: 171.0215 Acc: 39.6020\n",
            "val Loss: 124.2036 Acc: 56.0280\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 115.2973 Acc: 59.2220\n",
            "val Loss: 100.6092 Acc: 64.5460\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 98.6149 Acc: 65.4840\n",
            "val Loss: 87.9144 Acc: 68.9660\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 89.6740 Acc: 68.5860\n",
            "val Loss: 80.6571 Acc: 71.7560\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 83.2938 Acc: 71.0540\n",
            "val Loss: 74.8269 Acc: 73.8040\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 78.2269 Acc: 72.6600\n",
            "val Loss: 70.5875 Acc: 75.2280\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 74.1491 Acc: 74.0680\n",
            "val Loss: 66.9405 Acc: 76.3820\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 71.8288 Acc: 74.8120\n",
            "val Loss: 65.5254 Acc: 76.8900\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 70.7564 Acc: 75.2800\n",
            "val Loss: 64.8558 Acc: 77.0900\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 70.3388 Acc: 75.4520\n",
            "val Loss: 64.7280 Acc: 77.2780\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 69.7811 Acc: 75.7100\n",
            "val Loss: 63.5575 Acc: 77.8300\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 69.2579 Acc: 75.8660\n",
            "val Loss: 64.0891 Acc: 77.4960\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 68.8901 Acc: 76.0560\n",
            "val Loss: 63.6048 Acc: 77.6920\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 68.5985 Acc: 76.1320\n",
            "val Loss: 62.9927 Acc: 77.9140\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 68.4082 Acc: 76.2060\n",
            "val Loss: 63.2205 Acc: 77.7240\n",
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 68.3768 Acc: 76.0220\n",
            "val Loss: 62.8012 Acc: 78.1300\n",
            "\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 68.6509 Acc: 75.8500\n",
            "val Loss: 62.7783 Acc: 77.9260\n",
            "\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 68.3624 Acc: 76.0080\n",
            "val Loss: 63.0599 Acc: 78.1700\n",
            "\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 68.2410 Acc: 76.1580\n",
            "val Loss: 62.8662 Acc: 77.8120\n",
            "\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 68.1711 Acc: 76.1620\n",
            "val Loss: 62.3580 Acc: 78.0920\n",
            "\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 67.9016 Acc: 76.3700\n",
            "val Loss: 62.5193 Acc: 78.0220\n",
            "\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 68.0788 Acc: 76.1780\n",
            "val Loss: 62.8129 Acc: 78.0420\n",
            "\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 67.7115 Acc: 76.4160\n",
            "val Loss: 62.6018 Acc: 78.0700\n",
            "\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 68.3190 Acc: 76.0140\n",
            "val Loss: 62.9530 Acc: 78.1880\n",
            "\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 68.0119 Acc: 76.2500\n",
            "val Loss: 62.6378 Acc: 78.2680\n",
            "\n",
            "Training complete in 19m 26s\n",
            "Best val Acc: 78.268000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 검증"
      ],
      "metadata": {
        "id": "-0RTm5dLJwpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model_ft(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the model on the test images: {} %'.format(100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5tqXqvDJuyz",
        "outputId": "64cd10c7-58c7-4424-d2b6-bb633a92bda9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on the test images: 76.95 %\n"
          ]
        }
      ]
    }
  ]
}